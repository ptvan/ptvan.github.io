---
layout: post
title: Neural network noodling
---

One of the interesting and frustrating problems in modeling complex data is overfitting. The solution often involves a combination of picking the right tools, then knowing how to interpret their output.  In a neural network context once you've picked the appropriate [architecture](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464), the right [activation functions](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/), you may need to implement [dropout](http://jmlr.org/papers/v15/srivastava14a.html).

### But how does it work, really ?

One of the things I took away from my time in graduate school was the importance of understanding things from first principles. So I really enjoyed reading [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning), which proved a good complement to the more detail-oriented [Neural Smithing](https://mitpress.mit.edu/books/neural-smithing).
